{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29531 entries, 0 to 29530\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   City          29531 non-null  object \n",
      " 1   Date          29531 non-null  object \n",
      " 2   PM2.5         24933 non-null  float64\n",
      " 3   PM10          18391 non-null  float64\n",
      " 4   NO            25949 non-null  float64\n",
      " 5   NO2           25946 non-null  float64\n",
      " 6   NOx           25346 non-null  float64\n",
      " 7   NH3           19203 non-null  float64\n",
      " 8   CO            27472 non-null  float64\n",
      " 9   SO2           25677 non-null  float64\n",
      " 10  O3            25509 non-null  float64\n",
      " 11  Benzene       23908 non-null  float64\n",
      " 12  Toluene       21490 non-null  float64\n",
      " 13  Xylene        11422 non-null  float64\n",
      " 14  AQI           24850 non-null  float64\n",
      " 15  AQI_Bucket    24850 non-null  object \n",
      " 16  Demographics  29531 non-null  object \n",
      "dtypes: float64(13), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "        City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO    SO2  \\\n",
      "0  Ahmedabad  01-01-2015    NaN   NaN   0.92  18.22  17.15  NaN   0.92  27.64   \n",
      "1  Ahmedabad  02-01-2015    NaN   NaN   0.97  15.69  16.46  NaN   0.97  24.55   \n",
      "2  Ahmedabad  03-01-2015    NaN   NaN  17.40  19.30  29.70  NaN  17.40  29.07   \n",
      "3  Ahmedabad  04-01-2015    NaN   NaN   1.70  18.48  17.97  NaN   1.70  18.59   \n",
      "4  Ahmedabad  05-01-2015    NaN   NaN  22.10  21.42  37.76  NaN  22.10  39.33   \n",
      "\n",
      "       O3  Benzene  Toluene  Xylene  AQI AQI_Bucket Demographics  \n",
      "0  133.36     0.00     0.02    0.00  NaN        NaN   industrial  \n",
      "1   34.06     3.68     5.50    3.77  NaN        NaN  residential  \n",
      "2   30.70     6.80    16.40    2.25  NaN        NaN  residential  \n",
      "3   36.08     4.43    10.14    1.00  NaN        NaN  residential  \n",
      "4   39.31     7.01    18.89    2.78  NaN        NaN  residential  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/asus/Downloads/Air-Quality-Index--AQI--main/Air-Quality-Index--AQI--main/city_day.csv')\n",
    "\n",
    "# Display basic information about the dataset to understand the structure\n",
    "print(data.info())\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where demographic data is missing\n",
    "data = data.dropna(subset=['Demographics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (pollutant columns) and target (demographics)\n",
    "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene']\n",
    "X = data[features]\n",
    "y = data['Demographics']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the features with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical target variable (Demographics)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y_encoded)), activation='softmax'))  # Output layer with softmax for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a suitable loss function and optimizer for classification\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1182/1182 [==============================] - 4s 3ms/step - loss: 0.5650 - accuracy: 0.7045 - val_loss: 0.5331 - val_accuracy: 0.7090\n",
      "Epoch 2/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7138 - val_loss: 0.5258 - val_accuracy: 0.7090\n",
      "Epoch 3/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.5185 - accuracy: 0.7135 - val_loss: 0.5222 - val_accuracy: 0.7090\n",
      "Epoch 4/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.5156 - accuracy: 0.7122 - val_loss: 0.5156 - val_accuracy: 0.7147\n",
      "Epoch 5/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.5109 - accuracy: 0.7140 - val_loss: 0.5223 - val_accuracy: 0.7069\n",
      "Epoch 6/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.5071 - accuracy: 0.7168 - val_loss: 0.5113 - val_accuracy: 0.7105\n",
      "Epoch 7/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.5044 - accuracy: 0.7182 - val_loss: 0.5134 - val_accuracy: 0.7096\n",
      "Epoch 8/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.5021 - accuracy: 0.7140 - val_loss: 0.5098 - val_accuracy: 0.7065\n",
      "Epoch 9/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.5002 - accuracy: 0.7184 - val_loss: 0.5101 - val_accuracy: 0.7060\n",
      "Epoch 10/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4973 - accuracy: 0.7190 - val_loss: 0.5112 - val_accuracy: 0.7043\n",
      "Epoch 11/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.7211 - val_loss: 0.5132 - val_accuracy: 0.7109\n",
      "Epoch 12/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4943 - accuracy: 0.7187 - val_loss: 0.5111 - val_accuracy: 0.7039\n",
      "Epoch 13/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4916 - accuracy: 0.7183 - val_loss: 0.5091 - val_accuracy: 0.7124\n",
      "Epoch 14/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4905 - accuracy: 0.7203 - val_loss: 0.5087 - val_accuracy: 0.7039\n",
      "Epoch 15/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4892 - accuracy: 0.7188 - val_loss: 0.5105 - val_accuracy: 0.7101\n",
      "Epoch 16/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4870 - accuracy: 0.7211 - val_loss: 0.5107 - val_accuracy: 0.7065\n",
      "Epoch 17/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4860 - accuracy: 0.7214 - val_loss: 0.5127 - val_accuracy: 0.7120\n",
      "Epoch 18/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4839 - accuracy: 0.7220 - val_loss: 0.5120 - val_accuracy: 0.7126\n",
      "Epoch 19/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4829 - accuracy: 0.7237 - val_loss: 0.5055 - val_accuracy: 0.7077\n",
      "Epoch 20/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4804 - accuracy: 0.7248 - val_loss: 0.5082 - val_accuracy: 0.7124\n",
      "Epoch 21/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4796 - accuracy: 0.7232 - val_loss: 0.5135 - val_accuracy: 0.7039\n",
      "Epoch 22/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4789 - accuracy: 0.7223 - val_loss: 0.5084 - val_accuracy: 0.7071\n",
      "Epoch 23/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4766 - accuracy: 0.7235 - val_loss: 0.5153 - val_accuracy: 0.7096\n",
      "Epoch 24/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4756 - accuracy: 0.7228 - val_loss: 0.5107 - val_accuracy: 0.7033\n",
      "Epoch 25/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4747 - accuracy: 0.7258 - val_loss: 0.5127 - val_accuracy: 0.7134\n",
      "Epoch 26/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4730 - accuracy: 0.7271 - val_loss: 0.5134 - val_accuracy: 0.7156\n",
      "Epoch 27/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4713 - accuracy: 0.7267 - val_loss: 0.5082 - val_accuracy: 0.7079\n",
      "Epoch 28/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4701 - accuracy: 0.7261 - val_loss: 0.5117 - val_accuracy: 0.7151\n",
      "Epoch 29/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.7282 - val_loss: 0.5141 - val_accuracy: 0.7084\n",
      "Epoch 30/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4695 - accuracy: 0.7253 - val_loss: 0.5172 - val_accuracy: 0.7132\n",
      "Epoch 31/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4681 - accuracy: 0.7280 - val_loss: 0.5176 - val_accuracy: 0.7056\n",
      "Epoch 32/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.7268 - val_loss: 0.5179 - val_accuracy: 0.7071\n",
      "Epoch 33/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4650 - accuracy: 0.7284 - val_loss: 0.5258 - val_accuracy: 0.7050\n",
      "Epoch 34/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4652 - accuracy: 0.7263 - val_loss: 0.5132 - val_accuracy: 0.7090\n",
      "Epoch 35/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.7292 - val_loss: 0.5234 - val_accuracy: 0.6982\n",
      "Epoch 36/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4616 - accuracy: 0.7315 - val_loss: 0.5165 - val_accuracy: 0.6969\n",
      "Epoch 37/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4610 - accuracy: 0.7299 - val_loss: 0.5205 - val_accuracy: 0.6980\n",
      "Epoch 38/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4601 - accuracy: 0.7322 - val_loss: 0.5177 - val_accuracy: 0.6961\n",
      "Epoch 39/50\n",
      "1182/1182 [==============================] - 2s 1ms/step - loss: 0.4596 - accuracy: 0.7322 - val_loss: 0.5227 - val_accuracy: 0.6982\n",
      "Epoch 40/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.7331 - val_loss: 0.5234 - val_accuracy: 0.6978\n",
      "Epoch 41/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4581 - accuracy: 0.7321 - val_loss: 0.5263 - val_accuracy: 0.6961\n",
      "Epoch 42/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.7323 - val_loss: 0.5230 - val_accuracy: 0.7065\n",
      "Epoch 43/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4561 - accuracy: 0.7326 - val_loss: 0.5290 - val_accuracy: 0.6995\n",
      "Epoch 44/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4551 - accuracy: 0.7380 - val_loss: 0.5285 - val_accuracy: 0.6999\n",
      "Epoch 45/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4544 - accuracy: 0.7327 - val_loss: 0.5279 - val_accuracy: 0.6954\n",
      "Epoch 46/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.7334 - val_loss: 0.5285 - val_accuracy: 0.7031\n",
      "Epoch 47/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.7333 - val_loss: 0.5344 - val_accuracy: 0.7020\n",
      "Epoch 48/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.7329 - val_loss: 0.5328 - val_accuracy: 0.7039\n",
      "Epoch 49/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7358 - val_loss: 0.5363 - val_accuracy: 0.6885\n",
      "Epoch 50/50\n",
      "1182/1182 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.7339 - val_loss: 0.5388 - val_accuracy: 0.6897\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 1ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  industrial       0.53      0.59      0.56      1893\n",
      " residential       0.80      0.75      0.77      4014\n",
      "\n",
      "    accuracy                           0.70      5907\n",
      "   macro avg       0.66      0.67      0.67      5907\n",
      "weighted avg       0.71      0.70      0.70      5907\n",
      "\n",
      "Accuracy: 0.7003555104113763\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Display classification report and accuracy score\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESIDENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted Demographic: industrial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the sample data point based on the provided details for Amaravati\n",
    "sample_data = [\n",
    "    54.73,  # PM2.5\n",
    "    94.12,  # PM10\n",
    "    3.49,   # NO\n",
    "    12.79,  # NO2\n",
    "    9.73,   # NOx\n",
    "    22.79,  # NH3\n",
    "    0.58,   # CO\n",
    "    8.21,   # SO2\n",
    "    30.21,  # O3\n",
    "    0.08,   # Benzene\n",
    "    2.23,   # Toluene\n",
    "    0.15    # Xylene\n",
    "]\n",
    "\n",
    "# Convert sample data to a DataFrame for preprocessing\n",
    "sample_df = pd.DataFrame([sample_data], columns=features)\n",
    "\n",
    "# Impute any missing values in the sample data (if necessary)\n",
    "sample_df = pd.DataFrame(imputer.transform(sample_df), columns=features)\n",
    "\n",
    "# Scale the sample data using the same scaler\n",
    "sample_scaled = scaler.transform(sample_df)\n",
    "\n",
    "# Predict the demographic category (residential in this case)\n",
    "predicted_class = model.predict(sample_scaled)\n",
    "predicted_class_label = label_encoder.inverse_transform([np.argmax(predicted_class)])\n",
    "\n",
    "print(f'Predicted Demographic: {predicted_class_label[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDUSTRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted Demographic: industrial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the sample data point based on the provided details for Amaravati on 20-02-2018\n",
    "sample_data = [\n",
    "    50.91,  # PM2.5\n",
    "    99.84,  # PM10\n",
    "    4.55,   # NO\n",
    "    16.33,  # NO2\n",
    "    12.39,  # NOx\n",
    "    23.18,  # NH3\n",
    "    0.64,   # CO\n",
    "    10.34,  # SO2\n",
    "    26.24,  # O3\n",
    "    0.1,    # Benzene\n",
    "    2.51,   # Toluene\n",
    "    0.1     # Xylene\n",
    "]\n",
    "\n",
    "# Convert sample data to a DataFrame for preprocessing\n",
    "sample_df = pd.DataFrame([sample_data], columns=features)\n",
    "\n",
    "# Impute any missing values in the sample data (if necessary)\n",
    "sample_df = pd.DataFrame(imputer.transform(sample_df), columns=features)\n",
    "\n",
    "# Scale the sample data using the same scaler\n",
    "sample_scaled = scaler.transform(sample_df)\n",
    "\n",
    "# Predict the demographic category (residential in this case)\n",
    "predicted_class = model.predict(sample_scaled)\n",
    "predicted_class_label = label_encoder.inverse_transform([np.argmax(predicted_class)])\n",
    "\n",
    "print(f'Predicted Demographic: {predicted_class_label[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDUSTRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted Demographic: residential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the sample data point based on the provided details for Amaravati on 21-02-2018\n",
    "sample_data = [\n",
    "    38.5,   # PM2.5\n",
    "    106.7,  # PM10\n",
    "    4.5,    # NO\n",
    "    16.82,  # NO2\n",
    "    12.69,  # NOx\n",
    "    19.54,  # NH3\n",
    "    0.58,   # CO\n",
    "    11.02,  # SO2\n",
    "    26.62,  # O3\n",
    "    0.1,    # Benzene\n",
    "    2.68,   # Toluene\n",
    "    0.11    # Xylene\n",
    "]\n",
    "\n",
    "# Convert sample data to a DataFrame for preprocessing\n",
    "sample_df = pd.DataFrame([sample_data], columns=features)\n",
    "\n",
    "# Impute any missing values in the sample data (if necessary)\n",
    "sample_df = pd.DataFrame(imputer.transform(sample_df), columns=features)\n",
    "\n",
    "# Scale the sample data using the same scaler\n",
    "sample_scaled = scaler.transform(sample_df)\n",
    "\n",
    "# Predict the demographic category (residential in this case)\n",
    "predicted_class = model.predict(sample_scaled)\n",
    "predicted_class_label = label_encoder.inverse_transform([np.argmax(predicted_class)])\n",
    "\n",
    "print(f'Predicted Demographic: {predicted_class_label[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESIDENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted Demographic: residential\n"
     ]
    }
   ],
   "source": [
    "# Define the sample data point based on the provided details for Amaravati on 22-02-2018\n",
    "sample_data = [\n",
    "    32.21,  # PM2.5\n",
    "    107.43, # PM10\n",
    "    7.39,   # NO\n",
    "    17.33,  # NO2\n",
    "    15.32,  # NOx\n",
    "    18.13,  # NH3\n",
    "    0.6,    # CO\n",
    "    11.81,  # SO2\n",
    "    24.84,  # O3\n",
    "    0.12,   # Benzene\n",
    "    3.28,   # Toluene\n",
    "    0.13    # Xylene\n",
    "]\n",
    "\n",
    "# Convert sample data to a DataFrame for preprocessing\n",
    "sample_df = pd.DataFrame([sample_data], columns=features)\n",
    "\n",
    "# Impute any missing values in the sample data (if necessary)\n",
    "sample_df = pd.DataFrame(imputer.transform(sample_df), columns=features)\n",
    "\n",
    "# Scale the sample data using the same scaler\n",
    "sample_scaled = scaler.transform(sample_df)\n",
    "\n",
    "# Predict the demographic category (residential in this case)\n",
    "predicted_class = model.predict(sample_scaled)\n",
    "predicted_class_label = label_encoder.inverse_transform([np.argmax(predicted_class)])\n",
    "\n",
    "print(f'Predicted Demographic: {predicted_class_label[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESIDENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted Demographic: residential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the sample data point based on the provided details for Amaravati on 23-02-2018\n",
    "sample_data = [\n",
    "    35.36,  # PM2.5\n",
    "    107.25, # PM10\n",
    "    6.13,   # NO\n",
    "    17.75,  # NO2\n",
    "    14.52,  # NOx\n",
    "    16.57,  # NH3\n",
    "    0.85,   # CO\n",
    "    10.87,  # SO2\n",
    "    23.99,  # O3\n",
    "    0.09,   # Benzene\n",
    "    2.92,   # Toluene\n",
    "    0.2     # Xylene\n",
    "]\n",
    "\n",
    "# Convert sample data to a DataFrame for preprocessing\n",
    "sample_df = pd.DataFrame([sample_data], columns=features)\n",
    "\n",
    "# Impute any missing values in the sample data (if necessary)\n",
    "sample_df = pd.DataFrame(imputer.transform(sample_df), columns=features)\n",
    "\n",
    "# Scale the sample data using the same scaler\n",
    "sample_scaled = scaler.transform(sample_df)\n",
    "\n",
    "# Predict the demographic category (residential in this case)\n",
    "predicted_class = model.predict(sample_scaled)\n",
    "predicted_class_label = label_encoder.inverse_transform([np.argmax(predicted_class)])\n",
    "\n",
    "print(f'Predicted Demographic: {predicted_class_label[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
